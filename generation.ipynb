{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc45cf37-dff8-4599-8b75-d56ac73113c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befaa4e9-8870-46ed-9b28-78e86b6fe367",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_path = 'assets/Folly Audio/Meditation VO - Mindful Beathing.mp3'\n",
    "music_path = 'assets/Folly Audio/Meditation Music_moderatearousal.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c425894-814d-43f4-adb2-38dd751de09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import src.speech\n",
    "# reload(src.speech)\n",
    "# from src.speech import SpeechInformationRetreiver\n",
    "\n",
    "\n",
    "# sir = SpeechInformationRetreiver(\n",
    "#     model_name='stt_en_fastconformer_hybrid_large_streaming_1040ms',\n",
    "#     lookahead_size=1040,\n",
    "#     decoder_type='rnnt',\n",
    "#     num_keywords=10,\n",
    "#     device='cuda'\n",
    "# )\n",
    "# speech_segments = sir(speech_path, max_dist=5., extract_kw=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffedc7d1-a940-4a27-87b7-d31bfb8ac4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from src.music.mir import MusicInformationRetreiver\n",
    "# from src.music.bridge import MusicBridge\n",
    "\n",
    "\n",
    "# mir = MusicInformationRetreiver(weights_path='mir_weights/', segment_threshold=0.1)\n",
    "# music_segments = mir(music_path, class_threshold=0.3, verbpose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956f7b59-5af2-437c-9dfe-5ce11cfc3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_segments = [{'start': 0,\n",
    "  'end': 139.84,\n",
    "  'duration': 139.84,\n",
    "  'valence': 0.0005982993,\n",
    "  'arousal': 0.001197161,\n",
    "  'text': 'ambient, electronic, piano, synthesizer'},\n",
    " {'start': 139.84,\n",
    "  'end': 291.072,\n",
    "  'duration': 151.232,\n",
    "  'valence': 0.0008024101,\n",
    "  'arousal': 0.0016852224,\n",
    "  'text': 'ambient, chillout, electronic, piano, synthesizer'},\n",
    " {'start': 291.072,\n",
    "  'end': 426.08,\n",
    "  'duration': 135.00799999999998,\n",
    "  'valence': 0.00031344328,\n",
    "  'arousal': 0.0008951402,\n",
    "  'text': 'ambient, chillout, electronic, synthesizer'},\n",
    " {'start': 426.08,\n",
    "  'end': 560.736,\n",
    "  'duration': 134.656,\n",
    "  'valence': 0.0019070618,\n",
    "  'arousal': 0.0024938928,\n",
    "  'text': 'ambient, chillout, electronic, piano, synthesizer'},\n",
    " {'start': 560.736,\n",
    "  'end': 632.16,\n",
    "  'duration': 71.42399999999998,\n",
    "  'valence': 0.0007020948,\n",
    "  'arousal': 0.0014097905,\n",
    "  'text': 'ambient, chillout, electronic, piano, synthesizer'},\n",
    " {'start': 632.16,\n",
    "  'end': 873.44,\n",
    "  'duration': 241.2800000000001,\n",
    "  'valence': 0.002704294,\n",
    "  'arousal': 0.0037417596,\n",
    "  'text': 'ambient, bass, piano'},\n",
    " {'start': 873.44,\n",
    "  'end': 936.059875,\n",
    "  'duration': 62.61987499999998,\n",
    "  'valence': 0.0033889317,\n",
    "  'arousal': 0.0044924943,\n",
    "  'text': 'piano'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651d0dd4-b6a0-41b1-8617-6e4787ed9bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speech_segments = [{'text': 'hello and welcome to your resonance r xes',\n",
    "  'start': 35.85590062111801,\n",
    "  'end': 41.4583850931677,\n",
    "  'duration': 5.602484472049689},\n",
    " {'text': ' guided meditation',\n",
    "  'start': 42.57888198757764,\n",
    "  'end': 43.69937888198758,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' hi mandrew',\n",
    "  'start': 47.06086956521739,\n",
    "  'end': 48.18136645962733,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' i am here to guide you through a transformative journey',\n",
    "  'start': 50.422360248447205,\n",
    "  'end': 52.66335403726708,\n",
    "  'duration': 2.240993788819871},\n",
    " {'text': ' where we will be embracing',\n",
    "  'start': 54.904347826086955,\n",
    "  'end': 56.024844720496894,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' the powerful practice of mindfulness',\n",
    "  'start': 57.145341614906826,\n",
    "  'end': 61.62732919254658,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' focusing on our breath',\n",
    "  'start': 62.74782608695652,\n",
    "  'end': 67.22981366459626,\n",
    "  'duration': 4.481987577639742},\n",
    " {'text': ' this practice',\n",
    "  'start': 73.9527950310559,\n",
    "  'end': 75.07329192546584,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' is designed with you and mine',\n",
    "  'start': 77.31428571428572,\n",
    "  'end': 78.43478260869564,\n",
    "  'duration': 1.120496894409925},\n",
    " {'text': ' aiming to bring moments',\n",
    "  'start': 81.79627329192546,\n",
    "  'end': 82.9167701863354,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' of peace',\n",
    "  'start': 84.03726708074534,\n",
    "  'end': 85.15776397515528,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' relaxation',\n",
    "  'start': 87.39875776397515,\n",
    "  'end': 88.5192546583851,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' and clarity',\n",
    "  'start': 89.63975155279502,\n",
    "  'end': 90.76024844720496,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': \" let's start by finding a comfortable spot\",\n",
    "  'start': 99.72422360248447,\n",
    "  'end': 103.08571428571427,\n",
    "  'duration': 3.3614906832298033},\n",
    " {'text': ' where you can sit',\n",
    "  'start': 104.20621118012421,\n",
    "  'end': 105.32670807453415,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' or lie down',\n",
    "  'start': 106.44720496894409,\n",
    "  'end': 107.56770186335403,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' ensuring that distractions are minimal',\n",
    "  'start': 108.68819875776397,\n",
    "  'end': 112.04968944099379,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': \" once you've settled that your arms rest naturally\",\n",
    "  'start': 117.65217391304347,\n",
    "  'end': 122.13416149068323,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' and have your legs in a relaxed position',\n",
    "  'start': 123.25465838509317,\n",
    "  'end': 126.61614906832297,\n",
    "  'duration': 3.3614906832298033},\n",
    " {'text': ' has we embark on this journey',\n",
    "  'start': 161.35155279503104,\n",
    "  'end': 163.59254658385092,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' begin by taking a few profound and rejuvenating breaths',\n",
    "  'start': 164.71304347826086,\n",
    "  'end': 170.31552795031055,\n",
    "  'duration': 5.602484472049696},\n",
    " {'text': ' inhal deeply',\n",
    "  'start': 173.67701863354037,\n",
    "  'end': 175.91801242236025,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' feeling your chest',\n",
    "  'start': 177.0385093167702,\n",
    "  'end': 178.15900621118013,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' and abdomen rise',\n",
    "  'start': 179.27950310559004,\n",
    "  'end': 180.39999999999998,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' and then exhale slowly',\n",
    "  'start': 183.7614906832298,\n",
    "  'end': 186.00248447204967,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' letting go if any strains',\n",
    "  'start': 187.1229813664596,\n",
    "  'end': 189.3639751552795,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' or worries with every breath',\n",
    "  'start': 190.48447204968943,\n",
    "  'end': 192.7254658385093,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' do this a couple times',\n",
    "  'start': 197.20745341614906,\n",
    "  'end': 199.44844720496894,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' immersing yourself in this present moment',\n",
    "  'start': 200.56894409937888,\n",
    "  'end': 203.93043478260867,\n",
    "  'duration': 3.361490683229789},\n",
    " {'text': ' disconnecting from any external stresses',\n",
    "  'start': 208.41242236024843,\n",
    "  'end': 211.77391304347825,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' feel the connection between your body',\n",
    "  'start': 215.13540372670806,\n",
    "  'end': 217.37639751552794,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' and its resting place',\n",
    "  'start': 218.49689440993788,\n",
    "  'end': 220.73788819875776,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' and the grounding sensation',\n",
    "  'start': 222.97888198757764,\n",
    "  'end': 225.21987577639752,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' of your feet touching the floor',\n",
    "  'start': 226.34037267080745,\n",
    "  'end': 229.70186335403724,\n",
    "  'duration': 3.361490683229789},\n",
    " {'text': \" our breath will be the anchor of today's meditation\",\n",
    "  'start': 292.4496894409938,\n",
    "  'end': 298.0521739130435,\n",
    "  'duration': 5.602484472049696},\n",
    " {'text': ' without altering it',\n",
    "  'start': 300.29316770186335,\n",
    "  'end': 302.53416149068323,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' observe its current rhythm',\n",
    "  'start': 303.65465838509317,\n",
    "  'end': 305.89565217391305,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' is it shallow',\n",
    "  'start': 308.1366459627329,\n",
    "  'end': 309.25714285714287,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' deep',\n",
    "  'start': 311.4981366459627,\n",
    "  'end': 312.6186335403726,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': \" fill the breath's journey as it enters and exits\",\n",
    "  'start': 317.1006211180124,\n",
    "  'end': 321.58260869565214,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' creating a rhythmic dance',\n",
    "  'start': 323.823602484472,\n",
    "  'end': 324.94409937888196,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' of inn',\n",
    "  'start': 326.0645962732919,\n",
    "  'end': 327.18509316770184,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' and about',\n",
    "  'start': 328.3055900621118,\n",
    "  'end': 329.4260869565217,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' reminiscent of gentle ocean waves',\n",
    "  'start': 332.78757763975153,\n",
    "  'end': 336.14906832298135,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' caressing the shore',\n",
    "  'start': 337.2695652173913,\n",
    "  'end': 339.51055900621117,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' present with this dance of breath',\n",
    "  'start': 343.9925465838509,\n",
    "  'end': 346.2335403726708,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' without any need to alter origin',\n",
    "  'start': 347.35403726708074,\n",
    "  'end': 350.71552795031056,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' simply',\n",
    "  'start': 354.0770186335404,\n",
    "  'end': 355.1975155279503,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' b',\n",
    "  'start': 356.31801242236025,\n",
    "  'end': 357.4385093167702,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' it is only human for our minds to wander',\n",
    "  'start': 414.583850931677,\n",
    "  'end': 417.9453416149068,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' and if it does',\n",
    "  'start': 419.06583850931673,\n",
    "  'end': 420.1863354037267,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' there is no need for concern',\n",
    "  'start': 421.3068322981366,\n",
    "  'end': 422.42732919254655,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' when you find yourself for mister whirlwind of thoughts or emotions',\n",
    "  'start': 426.9093167701863,\n",
    "  'end': 431.39130434782606,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' acknowledge them gently',\n",
    "  'start': 433.63229813664594,\n",
    "  'end': 435.8732919254658,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' and redirect your focus to the comforting rhythm of your breast',\n",
    "  'start': 436.99378881987576,\n",
    "  'end': 443.7167701863354,\n",
    "  'duration': 6.722981366459635},\n",
    " {'text': ' this practice is all about patience',\n",
    "  'start': 448.19875776397515,\n",
    "  'end': 451.56024844720497,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' kindness towards oneself',\n",
    "  'start': 452.6807453416149,\n",
    "  'end': 454.92173913043473,\n",
    "  'duration': 2.2409937888198215},\n",
    " {'text': ' even if distractions emerge repeatedly',\n",
    "  'start': 457.1627329192546,\n",
    "  'end': 460.5242236024844,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': \" that's perfectly fine\",\n",
    "  'start': 461.64472049689437,\n",
    "  'end': 463.88571428571424,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' all that matters is the gentle return to the rhythm of your breath',\n",
    "  'start': 467.24720496894406,\n",
    "  'end': 472.84968944099376,\n",
    "  'duration': 5.602484472049696},\n",
    " {'text': ' visualizes each breath',\n",
    "  'start': 476.2111801242236,\n",
    "  'end': 478.45217391304345,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' in',\n",
    "  'start': 480.69316770186333,\n",
    "  'end': 481.81366459627327,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' as a gentle reminder',\n",
    "  'start': 485.1751552795031,\n",
    "  'end': 487.41614906832297,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' of your commitment to this present moment',\n",
    "  'start': 488.5366459627329,\n",
    "  'end': 491.8981366459627,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': \" let's now shift our attention to the area around your navel\",\n",
    "  'start': 534.4770186335403,\n",
    "  'end': 538.95900621118,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' feel the sensation of your abdomen moving with every inhalation',\n",
    "  'start': 542.3204968944099,\n",
    "  'end': 549.0434782608695,\n",
    "  'duration': 6.722981366459635},\n",
    " {'text': ' descending with every exhalation',\n",
    "  'start': 552.4049689440993,\n",
    "  'end': 554.6459627329192,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' engaged deeply with these sensations',\n",
    "  'start': 559.127950310559,\n",
    "  'end': 561.3689440993788,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' perhaps mentally noting in on the inhale',\n",
    "  'start': 562.4894409937888,\n",
    "  'end': 566.9714285714285,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' and',\n",
    "  'start': 568.0919254658385,\n",
    "  'end': 569.2124223602484,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' exhale',\n",
    "  'start': 572.5739130434782,\n",
    "  'end': 573.6944099378882,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' fortify your attention',\n",
    "  'start': 574.8149068322981,\n",
    "  'end': 575.935403726708,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' throughout this session',\n",
    "  'start': 609.5503105590062,\n",
    "  'end': 611.7913043478261,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' embrace everything surfaces with warmth and acceptance',\n",
    "  'start': 612.911801242236,\n",
    "  'end': 618.5142857142857,\n",
    "  'duration': 5.602484472049696},\n",
    " {'text': ' of fleeting thought',\n",
    "  'start': 621.8757763975154,\n",
    "  'end': 622.9962732919254,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' an emotion',\n",
    "  'start': 624.1167701863353,\n",
    "  'end': 625.2372670807453,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' or a physical sensation',\n",
    "  'start': 626.3577639751552,\n",
    "  'end': 628.5987577639751,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' let it fall',\n",
    "  'start': 629.719254658385,\n",
    "  'end': 630.839751552795,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' when you identify them',\n",
    "  'start': 634.2012422360248,\n",
    "  'end': 636.4422360248446,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' rather than dwelling or resisting',\n",
    "  'start': 637.5627329192546,\n",
    "  'end': 639.8037267080745,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' kindly your focus back to your breath',\n",
    "  'start': 642.0447204968943,\n",
    "  'end': 645.4062111801242,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' these moments',\n",
    "  'start': 647.647204968944,\n",
    "  'end': 648.767701863354,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' these sensations',\n",
    "  'start': 651.0086956521739,\n",
    "  'end': 652.1291925465838,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' are all parts of this beautiful journey of mindfulness',\n",
    "  'start': 653.2496894409937,\n",
    "  'end': 657.7316770186335,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' with practice',\n",
    "  'start': 658.8521739130434,\n",
    "  'end': 659.9726708074534,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' this acceptance becomes second nature',\n",
    "  'start': 661.0931677018633,\n",
    "  'end': 664.4546583850931,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' illuminating idea',\n",
    "  'start': 665.5751552795031,\n",
    "  'end': 666.695652173913,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' within a new found peace',\n",
    "  'start': 667.8161490683229,\n",
    "  'end': 670.0571428571428,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' as draw this meditation to a close',\n",
    "  'start': 736.1664596273291,\n",
    "  'end': 739.5279503105589,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' gradually bringing your consciousness',\n",
    "  'start': 741.7689440993788,\n",
    "  'end': 744.0099378881987,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' back to the space around you',\n",
    "  'start': 745.1304347826086,\n",
    "  'end': 747.3714285714285,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' if your eyes were closed',\n",
    "  'start': 750.7329192546583,\n",
    "  'end': 752.9739130434782,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' allow them to flutter open gently',\n",
    "  'start': 754.0944099378881,\n",
    "  'end': 757.455900621118,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' reflect for a moment on how you feel',\n",
    "  'start': 760.8173913043478,\n",
    "  'end': 764.1788819875776,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' compared to when you started',\n",
    "  'start': 766.4198757763975,\n",
    "  'end': 768.6608695652174,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' do you sense a shift',\n",
    "  'start': 770.9018633540372,\n",
    "  'end': 773.1428571428571,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': 'fulness offers us a chance to realign',\n",
    "  'start': 784.3478260869565,\n",
    "  'end': 787.7093167701863,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' providing a haven of calm acceptance',\n",
    "  'start': 788.8298136645963,\n",
    "  'end': 791.0708074534161,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' in our bustling lives',\n",
    "  'start': 792.1913043478261,\n",
    "  'end': 794.432298136646,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': \" it's not about passive resignation\",\n",
    "  'start': 797.7937888198758,\n",
    "  'end': 800.0347826086957,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' but about granting us the clarity to act with intention',\n",
    "  'start': 801.1552795031056,\n",
    "  'end': 805.6372670807453,\n",
    "  'duration': 4.481987577639757},\n",
    " {'text': ' acceptance can beacon',\n",
    "  'start': 808.9987577639752,\n",
    "  'end': 812.360248447205,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' guiding us away from the needless stress',\n",
    "  'start': 814.6012422360247,\n",
    "  'end': 817.9627329192546,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' ushering in our realm of peace',\n",
    "  'start': 821.3242236024844,\n",
    "  'end': 823.5652173913043,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' thank yourself for dedicating this time to personal growth and tranquility',\n",
    "  'start': 829.167701863354,\n",
    "  'end': 835.8906832298136,\n",
    "  'duration': 6.722981366459635},\n",
    " {'text': ' this practice of',\n",
    "  'start': 840.3726708074533,\n",
    "  'end': 842.6136645962732,\n",
    "  'duration': 2.2409937888198783},\n",
    " {'text': ' always here',\n",
    "  'start': 844.8546583850931,\n",
    "  'end': 845.975155279503,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' waiting for you',\n",
    "  'start': 847.095652173913,\n",
    "  'end': 848.2161490683229,\n",
    "  'duration': 1.1204968944099392},\n",
    " {'text': ' ready to guide you back to a moment of serenity whenever you need',\n",
    "  'start': 849.3366459627329,\n",
    "  'end': 856.0596273291925,\n",
    "  'duration': 6.722981366459635},\n",
    " {'text': ' until an excession take care',\n",
    "  'start': 858.3006211180124,\n",
    "  'end': 861.6621118012422,\n",
    "  'duration': 3.3614906832298175},\n",
    " {'text': ' let the soothing rhythms of life carry you forward',\n",
    "  'start': 863.9031055900621,\n",
    "  'end': 868.3850931677018,\n",
    "  'duration': 4.481987577639757}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09473f5-b2ff-47c8-8047-4ed1ef59c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,s in enumerate(speech_segments):\n",
    "    s['style'] = 'Digital Art'\n",
    "    speech_segments[i] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5eba376-a657-47ca-ab7e-7c87d1429e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroush/.venv/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/soroush/.venv/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d46fff53014f14ba3727029685a710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import src.video.gen\n",
    "reload(src.video.gen)\n",
    "from src.video.gen import VideoGenerator\n",
    "\n",
    "\n",
    "\n",
    "video_gen = VideoGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a2a85e-7ba3-4843-a082-1ddc3b6198c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio activities captured\n",
      "latent vectors computed\n",
      "starting generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd718e157b7f42feb5ac29e66eac38a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
      "ffmpeg version 5.1.5-0+deb12u1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 12 (Debian 12.2.0-14)\n",
      "  configuration: --prefix=/usr --extra-version=0+deb12u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test-video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:00.80, start: 0.000000, bitrate: 2135 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 2135 kb/s, 10 fps, 10 tbr, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Input #1, mp3, from 'test-audio.mp3':\n",
      "  Metadata:\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:00.03, start: 0.025057, bitrate: 128 kb/s\n",
      "  Stream #1:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (mp3 (mp3float) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to 'test.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 512x512 [SAR 1:1 DAR 1:1], q=2-31, 2135 kb/s, 10 fps, 10 tbr, 10240 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 192 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 aac\n",
      "frame=  517 fps=343 q=-1.0 size=   14848kB time=00:00:51.60 bitrate=2357.3kbits/s speed=34.3x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged video_file and audio_file into test.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  608 fps=326 q=-1.0 Lsize=   17182kB time=00:01:00.70 bitrate=2318.9kbits/s speed=32.6x    \n",
      "video:15847kB audio:1312kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.135646%\n",
      "[aac @ 0x55abbdaff600] Qavg: 6233.718\n"
     ]
    }
   ],
   "source": [
    "_ = video_gen.generate(\n",
    "    speech_segments,\n",
    "    music_segments, \n",
    "    speech_path, \n",
    "    music_path, \n",
    "    percussive_reactivity=False,\n",
    "    batch_size=32, \n",
    "    duration=60, \n",
    "    guidance_scale=7.,\n",
    "    num_inference_steps=20,\n",
    "    fps=10,\n",
    "    save_path='test.mp4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e535d65-1133-479c-b6e7-72459fb3aaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroush/.venv/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/soroush/.venv/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "/home/soroush/.venv/lib/python3.11/site-packages/diffusers/models/vq_model.py:20: FutureWarning: `VQEncoderOutput` is deprecated and will be removed in version 0.31. Importing `VQEncoderOutput` from `diffusers.models.vq_model` is deprecated and this will be removed in a future version. Please use `from diffusers.models.autoencoders.vq_model import VQEncoderOutput`, instead.\n",
      "  deprecate(\"VQEncoderOutput\", \"0.31\", deprecation_message)\n",
      "/home/soroush/.venv/lib/python3.11/site-packages/diffusers/models/vq_model.py:25: FutureWarning: `VQModel` is deprecated and will be removed in version 0.31. Importing `VQModel` from `diffusers.models.vq_model` is deprecated and this will be removed in a future version. Please use `from diffusers.models.autoencoders.vq_model import VQModel`, instead.\n",
      "  deprecate(\"VQModel\", \"0.31\", deprecation_message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27b77d9a9be4e4caf7fc02cc2a60106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import AutoPipelineForInpainting\n",
    "\n",
    "pipeline = AutoPipelineForInpainting.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-inpainting\", \n",
    "    torch_dtype=torch.float16, \n",
    "    variant=\"fp16\",\n",
    "    safety_checker=None\n",
    ").to('cuda')\n",
    "pipeline.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539419b-e2de-4ab5-994e-9e6eb6e15134",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d2abc08-d16c-4e6e-8d1f-68e6da18ce78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91be8d7248d54c5b88b645f4bee538a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(duration \u001b[38;5;241m*\u001b[39m fps)):\n\u001b[1;32m     38\u001b[0m     curr, mask \u001b[38;5;241m=\u001b[39m shrink_and_paste_on_blank(frames[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# strength=0.999,\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py:1384\u001b[0m, in \u001b[0;36mStableDiffusionInpaintPipeline.__call__\u001b[0;34m(self, prompt, image, mask_image, masked_image_latents, height, width, padding_mask_crop, strength, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     latent_model_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([latent_model_input, mask, masked_image_latents], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[0;32m-> 1384\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_classifier_free_guidance:\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/diffusers/models/unets/unet_2d_condition.py:1285\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         sample \u001b[38;5;241m=\u001b[39m upsample_block(\n\u001b[1;32m   1275\u001b[0m             hidden_states\u001b[38;5;241m=\u001b[39msample,\n\u001b[1;32m   1276\u001b[0m             temb\u001b[38;5;241m=\u001b[39memb,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[1;32m   1283\u001b[0m         )\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1285\u001b[0m         sample \u001b[38;5;241m=\u001b[39m \u001b[43mupsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mres_hidden_states_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mupsample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;66;03m# 6. post-process\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_norm_out:\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/diffusers/models/unets/unet_2d_blocks.py:2677\u001b[0m, in \u001b[0;36mUpBlock2D.forward\u001b[0;34m(self, hidden_states, res_hidden_states_tuple, temb, upsample_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2676\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n\u001b[0;32m-> 2677\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mupsampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsample_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/diffusers/models/upsampling.py:180\u001b[0m, in \u001b[0;36mUpsample2D.forward\u001b[0;34m(self, hidden_states, output_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_conv:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 180\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mConv2d_0(hidden_states)\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "\n",
    "def shrink_and_paste_on_blank(current_image, mask_width):\n",
    "   \n",
    "    height = current_image.height\n",
    "    width = current_image.width\n",
    "\n",
    "    # shrink down by mask_width\n",
    "    prev_image = current_image.resize((height - 2 * mask_width, width - 2 * mask_width))\n",
    "    prev_image = prev_image.convert(\"RGBA\")\n",
    "    prev_image = np.array(prev_image)\n",
    "\n",
    "    # create blank non-transparent image\n",
    "    blank_image = np.array(current_image.convert(\"RGBA\")) * 0\n",
    "    blank_image[:, :, 3] = 1\n",
    "\n",
    "    # paste shrinked onto blank\n",
    "    blank_image[mask_width : height - mask_width, mask_width : width - mask_width, :] = prev_image\n",
    "    prev_image = Image.fromarray(blank_image)\n",
    "\n",
    "    mask_image = np.array(prev_image)[:, :, 3]\n",
    "    mask_image = Image.fromarray(255 - mask_image).convert(\"RGB\")\n",
    "\n",
    "    return prev_image.convert(\"RGB\"), mask_image\n",
    "\n",
    "\n",
    "duration = 60\n",
    "fps = 10\n",
    "n = duration * fps\n",
    "init_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\n",
    "frames = [init_image]\n",
    "generator = torch.Generator(\"cuda\").manual_seed(7)\n",
    "\n",
    "for _ in tqdm(range(duration * fps)):\n",
    "    curr, mask = shrink_and_paste_on_blank(frames[-1], 20)\n",
    "    frames += pipeline(\n",
    "        prompt='', \n",
    "        image=curr, \n",
    "        mask_image=mask, \n",
    "        generator=generator,\n",
    "        # strength=0.999,\n",
    "        num_inference_steps=20\n",
    "    ).images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12a5a2ce-86bd-4a89-a90d-fe0690129627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # For MP4\n",
    "video_writer = cv2.VideoWriter(\n",
    "    'zoom.mp4', fourcc, fps, (512, 512)\n",
    ")\n",
    "for frame in frames:\n",
    "    frame = np.array(frame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    video_writer.write(frame)\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757cede-8c4c-42e1-b9ad-ba26ac732030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
