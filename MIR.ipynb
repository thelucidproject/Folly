{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "247f8b49-84e5-48ff-9d40-578114016abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcee2007-ff81-49ef-b4de-5acacfc4753c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `mir_weights//discogs-effnet-bs64-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `mir_weights//mtg_jamendo_genre-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `mir_weights//mtg_jamendo_instrument-discogs-effnet-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `mir_weights//msd-musicnn-1.pb`\n",
      "[   INFO   ] TensorflowPredict: Successfully loaded graph file: `mir_weights//emomusic-msd-musicnn-2.pb`\n"
     ]
    }
   ],
   "source": [
    "import src.music.mir\n",
    "reload(src.music.mir)\n",
    "from src.music.mir import MusicInformationRetreiver\n",
    "\n",
    "mir = MusicInformationRetreiver(weights_path='mir_weights/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75250751-3777-4e76-b304-18bab3ec3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://27fa892b90ed017928.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://27fa892b90ed017928.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_segments(segments):\n",
    "    segments.sort(key=lambda x: x['start'])\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5), sharex=True)\n",
    "\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(segments)))\n",
    "    for idx, seg in enumerate(segments):\n",
    "        rect = plt.Rectangle(\n",
    "            xy=(seg['start'], 0), \n",
    "            width=seg['end'] - seg['start'], \n",
    "            height=1, facecolor=colors[idx], alpha=0.5, edgecolor='black'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    ax.set_title('Segments')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_xlim(min(seg['start'] for seg in segments), max(seg['end'] for seg in segments))\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_emotions(segments):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    valence = []\n",
    "    arousal = []\n",
    "    ax.set_title('Emotion Dimenions')\n",
    "    for seg in segments:\n",
    "        valence += [np.mean(seg['valence'])]\n",
    "        arousal += [np.mean(seg['arousal'])]\n",
    "    ax.plot(valence, label='valence')\n",
    "    ax.plot(arousal, label='arousal')\n",
    "    plt.legend()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def music_fn(music_path, segment_threshold, instrument_threshold, genre_threshold):\n",
    "    segments = mir(\n",
    "        music_path, \n",
    "        segment_threshold=segment_threshold, \n",
    "        genre_threshold=genre_threshold, \n",
    "        inst_threshold=instrument_threshold, \n",
    "        add_segment_info=True,\n",
    "        progress_bar=gr.Progress().tqdm\n",
    "    )\n",
    "    seg_plot = plot_segments(segments)\n",
    "    emo_plot = plot_emotions(segments)\n",
    "    for seg in segments:\n",
    "        del seg['arousal']\n",
    "        del seg['valence']\n",
    "    return seg_plot, emo_plot, json.dumps(segments, indent=4)\n",
    "\n",
    "music_demo = gr.Interface(\n",
    "    fn=music_fn,\n",
    "    inputs=[\n",
    "        gr.Audio(label=\"Upload Music File\", type='filepath', sources='upload'),\n",
    "        gr.Slider(minimum=0.01, step=0.01, maximum=0.99, value=0.1, label=\"Segmentation Threshold\"),\n",
    "        gr.Slider(minimum=0.01, step=0.01, maximum=0.99, value=0.3, label=\"Instrumentation Threshold\"),\n",
    "        gr.Slider(minimum=0.01, step=0.01, maximum=0.99, value=0.3, label=\"Genre Threshold\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Plot(label=\"Music Segments\", format=\"png\"),\n",
    "        gr.Plot(label=\"Segment Emotion\", format=\"png\"),\n",
    "        gr.Text(label='Segments Details')\n",
    "    ]\n",
    ")\n",
    "music_demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f44591-babe-43b7-b5b7-ed1bdce8ac8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
