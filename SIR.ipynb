{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dcb2feb-a4b7-46a8-90b7-e4dc2fe6944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"nemo_logger\").setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a67a73-db49-48c5-b69c-ea2f02c20cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-21 19:47:06 nemo_logging:393] /home/soroush/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "      warnings.warn(\n",
      "    \n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n",
      "Some weights of EmotionDimensionModel were not initialized from the model checkpoint at audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-21 19:47:08 nemo_logging:381] Found existing object /home/soroush/.cache/torch/NeMo/NeMo_2.0.0rc2/stt_en_fastconformer_hybrid_large_streaming_1040ms/666909d8ac36ad698d0451f58f12594c/stt_en_fastconformer_hybrid_large_streaming_1040ms.nemo.\n",
      "[NeMo I 2024-08-21 19:47:08 nemo_logging:381] Re-using file from: /home/soroush/.cache/torch/NeMo/NeMo_2.0.0rc2/stt_en_fastconformer_hybrid_large_streaming_1040ms/666909d8ac36ad698d0451f58f12594c/stt_en_fastconformer_hybrid_large_streaming_1040ms.nemo\n",
      "[NeMo I 2024-08-21 19:47:08 nemo_logging:381] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2024-08-21 19:47:09 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-21 19:47:10 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath:\n",
      "    - - /raid/local//bucket1/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket2/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket3/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket4/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket5/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket6/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket7/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket8/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 25\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket1/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket2/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket3/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket4/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket5/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket6/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket7/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket8/audio__OP_0..8191_CL_.tar\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size:\n",
      "    - 72\n",
      "    - 64\n",
      "    - 56\n",
      "    - 48\n",
      "    - 40\n",
      "    - 32\n",
      "    - 24\n",
      "    - 16\n",
      "    \n",
      "[NeMo W 2024-08-21 19:47:10 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2024-08-21 19:47:10 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-21 19:47:10 nemo_logging:381] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-21 19:47:11 nemo_logging:393] /home/soroush/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-21 19:47:11 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n",
      "[NeMo I 2024-08-21 19:47:11 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-21 19:47:11 nemo_logging:393] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-21 19:47:12 nemo_logging:393] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/soroush/.cache/torch/NeMo/NeMo_2.0.0rc2/stt_en_fastconformer_hybrid_large_streaming_1040ms/666909d8ac36ad698d0451f58f12594c/stt_en_fastconformer_hybrid_large_streaming_1040ms.nemo.\n",
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-21 19:47:12 nemo_logging:393] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: null\n",
      "    compute_timestamps: null\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      tdt_include_duration_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "      loop_labels: true\n",
      "      use_cuda_graph_decoder: true\n",
      "      max_symbols: 10\n",
      "    beam:\n",
      "      beam_size: 5\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: false\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 2.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "      tsd_max_sym_exp: 50\n",
      "    temperature: 1.0\n",
      "    durations: []\n",
      "    big_blank_durations: []\n",
      "    \n",
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n",
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: null\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      tdt_include_duration_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "      loop_labels: true\n",
      "      use_cuda_graph_decoder: true\n",
      "      max_symbols: 10\n",
      "    beam:\n",
      "      beam_size: 5\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: false\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 2.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "      tsd_max_sym_exp: 50\n",
      "    temperature: 1.0\n",
      "    durations: []\n",
      "    big_blank_durations: []\n",
      "    \n",
      "[NeMo I 2024-08-21 19:47:12 nemo_logging:381] PADDING: 0\n"
     ]
    }
   ],
   "source": [
    "import src.speech.asr\n",
    "reload(src.speech.asr)\n",
    "from src.speech.asr import SpeechInformationRetreiver\n",
    "\n",
    "\n",
    "sir = SpeechInformationRetreiver(\n",
    "    model_name='stt_en_fastconformer_hybrid_large_streaming_1040ms',\n",
    "    lookahead_size=1040,\n",
    "    decoder_type='rnnt',\n",
    "    num_keywords=10,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ca5f71-8d47-49d2-a765-c2a5193fa1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "Running on public URL: https://fd68261469c85f0221.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://fd68261469c85f0221.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_segments(segments):\n",
    "    segments.sort(key=lambda x: x['start'])\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5), sharex=True)\n",
    "\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(segments)))\n",
    "    for idx, seg in enumerate(segments):\n",
    "        rect = plt.Rectangle(\n",
    "            xy=(seg['start'], 0), \n",
    "            width=seg['end'] - seg['start'], \n",
    "            height=1, facecolor=colors[idx], alpha=0.5, edgecolor='black'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    ax.set_title('Segments')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_xlim(min(seg['start'] for seg in segments), max(seg['end'] for seg in segments))\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_emotions(segments):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    valence = []\n",
    "    arousal = []\n",
    "    dominance = []\n",
    "    ax.set_title('Emotion Dimenions')\n",
    "    for seg in segments:\n",
    "        valence += [seg['valence']]\n",
    "        arousal += [seg['arousal']]\n",
    "        dominance += [seg['dominance']]\n",
    "    ax.plot(valence, label='valence')\n",
    "    ax.plot(arousal, label='arousal')\n",
    "    ax.plot(dominance, label='dominance')\n",
    "    plt.legend()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def speech_fn(speech_path, max_dist, extract_kw):\n",
    "    segments = sir(\n",
    "        speech_path, \n",
    "        add_emotion_info=True, \n",
    "        max_dist=max_dist, \n",
    "        extract_kw=extract_kw, \n",
    "        progress_bar=gr.Progress().tqdm\n",
    "    )\n",
    "    seg_plot = plot_segments(segments)\n",
    "    emo_plot = plot_emotions(segments)\n",
    "    for seg in segments:\n",
    "        del seg['arousal']\n",
    "        del seg['valence']\n",
    "        del seg['dominance']\n",
    "    return seg_plot, emo_plot, json.dumps(segments, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "speech_demo = gr.Interface(\n",
    "    fn=speech_fn,\n",
    "    inputs=[\n",
    "        gr.Audio(label=\"Upload Speech File\", type='filepath', sources='upload'),\n",
    "        gr.Slider(minimum=1., step=0.5, maximum=10, value=5, label=\"Segments Max Distance\"),\n",
    "        gr.Checkbox(label='extract_keywords', info='Extract Keywords')\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Plot(label=\"Speech Segments\", format=\"png\"),\n",
    "        gr.Plot(label=\"Segment Emotion\", format=\"png\"),\n",
    "        gr.TextArea(label='Segments Details')\n",
    "    ]\n",
    ")\n",
    "speech_demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7739429-64b0-4158-8d5a-4d061f9b133c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
