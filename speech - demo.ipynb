{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e379c826-7911-4ed7-8ecd-943876d7a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab9064e-ea23-4c19-ad80-d2011ba980e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-09 01:30:32 cloud:58] Found existing object /Users/soroush/.cache/torch/NeMo/NeMo_2.0.0rc1/stt_en_fastconformer_hybrid_large_streaming_1040ms/666909d8ac36ad698d0451f58f12594c/stt_en_fastconformer_hybrid_large_streaming_1040ms.nemo.\n",
      "[NeMo I 2024-07-09 01:30:32 cloud:64] Re-using file from: /Users/soroush/.cache/torch/NeMo/NeMo_2.0.0rc1/stt_en_fastconformer_hybrid_large_streaming_1040ms/666909d8ac36ad698d0451f58f12594c/stt_en_fastconformer_hybrid_large_streaming_1040ms.nemo\n",
      "[NeMo I 2024-07-09 01:30:32 common:826] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2024-07-09 01:30:33 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-09 01:30:33 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath:\n",
      "    - - /raid/local//bucket1/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket2/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket3/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket4/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket5/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket6/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket7/tarred_audio_manifest.json\n",
      "    - - /raid/local//bucket8/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 25\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket1/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket2/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket3/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket4/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket5/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket6/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket7/audio__OP_0..8191_CL_.tar\n",
      "    - - /data2/nemo_asr/nemo_asr_set_3.0//bucket8/audio__OP_0..8191_CL_.tar\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size:\n",
      "    - 72\n",
      "    - 64\n",
      "    - 56\n",
      "    - 48\n",
      "    - 40\n",
      "    - 32\n",
      "    - 24\n",
      "    - 16\n",
      "    \n",
      "[NeMo W 2024-07-09 01:30:33 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2024-07-09 01:30:33 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-09 01:30:33 features:305] PADDING: 0\n",
      "[NeMo I 2024-07-09 01:30:34 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n",
      "[NeMo I 2024-07-09 01:30:34 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-09 01:30:34 rnnt_loop_labels_computer:270] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-09 01:30:34 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-09 01:30:34 rnnt_loop_labels_computer:270] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-09 01:30:34 save_restore_connector:263] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /Users/soroush/.cache/torch/NeMo/NeMo_2.0.0rc1/stt_en_fastconformer_hybrid_large_streaming_1040ms/666909d8ac36ad698d0451f58f12594c/stt_en_fastconformer_hybrid_large_streaming_1040ms.nemo.\n",
      "[NeMo I 2024-07-09 01:30:34 hybrid_rnnt_ctc_bpe_models:422] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2024-07-09 01:30:34 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-09 01:30:34 rnnt_loop_labels_computer:270] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-09 01:30:34 hybrid_rnnt_ctc_bpe_models:457] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: null\n",
      "    compute_timestamps: null\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      tdt_include_duration_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "      loop_labels: true\n",
      "      use_cuda_graph_decoder: true\n",
      "      max_symbols: 10\n",
      "    beam:\n",
      "      beam_size: 5\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: false\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 2.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "      tsd_max_sym_exp: 50\n",
      "    temperature: 1.0\n",
      "    durations: []\n",
      "    big_blank_durations: []\n",
      "    \n",
      "[NeMo I 2024-07-09 01:30:34 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.001, 'clamp': -1.0}\n",
      "[NeMo I 2024-07-09 01:30:34 rnnt_decoding:730] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2024-07-09 01:30:34 hybrid_rnnt_ctc_bpe_models:457] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: null\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      tdt_include_duration_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "      loop_labels: true\n",
      "      use_cuda_graph_decoder: true\n",
      "      max_symbols: 10\n",
      "    beam:\n",
      "      beam_size: 5\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: false\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 2.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "      tsd_max_sym_exp: 50\n",
      "    temperature: 1.0\n",
      "    durations: []\n",
      "    big_blank_durations: []\n",
      "    \n",
      "[NeMo I 2024-07-09 01:30:34 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n",
      "Some weights of EmotionDimensionModel were not initialized from the model checkpoint at audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from ser import SER\n",
    "from asr import ASR\n",
    "\n",
    "\n",
    "asr_module = ASR(\n",
    "    model_name='stt_en_fastconformer_hybrid_large_streaming_1040ms',\n",
    "    lookahead_size=1040,\n",
    "    decoder_type='rnnt',\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "ser_module = SER(\n",
    "    chunk_size=asr_module.chunk_size, \n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272b08ef-0e17-471e-b4e8-45d4902a0d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63447f344be744698e3a16af820d9ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/803 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"welcome to this meditation journey where you will find calm amidst the turbulence of the seaman i'll be your guide a comfortable seated or lying position and gently close your eyes by taking a few deep breaths allowing your body to relax your mind to settle imagine yourself on a small vessel at sea gently being carried by the swells the whole ocean seems to be an upheaval around you yet beneath the surface the depth of the ocean is at rest the vastness of the ocean its waves rising falling but would feel the stillness at its core now select mantra resonates with you it could be a simple sound like any word or phrase that brings you peace as you begin to produce this mantra synchronize it with the rhythm of your breath with each repetition of yomantra allow the music to quiet your mind let the soothing melodies was overview crediting you deeper into a state of tranquillity feel the swells of the music mirroring the rise and fall of the ocean as you continue to produce your chosen mantra you immerse yourself in sound of your mantrea and the music feel yourself become more and more grounded like the sturdy vessel amidst the stormy sea let go of any tension or worries allowing yourself to surrender to the present moment with each breath and each repetition of your mantra allow the music to lead you into a state of deep rest feel the tension melting away from your body like the waves dissipating into the vast expanse of the ocean has you continue this practice how your body and mind begin to feel lighter than mortyself to fully surrender to the experience knowing you are safe and supported by the stillness at the depth of the ocean within you stay with this practice for a few more minutes allowing yourself to fully emerge in the tranquillity of this moment music mantra you to a place of profound peace serenity when you are ready return to the present moment gently bring your awareness back to your surroundings take a few deep breaths wiggle your fingers and toes and slowly open your eyes carry the sense of calm and stillness with you as you continue your day knowing that you can always return to the depth of the ocean within you whenever you need to find peace thank you for listening to\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr_module.transcribe_file(\n",
    "    'assets/LANDR- Meditation- Transcend 15 Mins-Balanced-Medium.mp3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870a151b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3c2b2295f84685b1f77b6581e8d05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, dims = ser_module.recognize_file(\n",
    "    '/Users/soroush/Desktop/LUCID/Folly/Speech/sample/LANDR- Meditation- Transcend 15 Mins-Balanced-Medium.mp3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846e8e84-fb69-4d1e-9f1c-4f44af0afff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_module._init_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd9e415-2c87-4202-9441-556bfe54197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available audio input devices:\n",
      "0 Soroushâ€™s iPhone Microphone\n",
      "1 MacBook Air Microphone\n",
      "3 Microsoft Teams Audio\n",
      "Please type input device ID:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    }
   ],
   "source": [
    "import stream\n",
    "reload(stream)\n",
    "from stream import Streamer\n",
    "\n",
    "streamer = Streamer(\n",
    "    chunk_size=asr_module.chunk_size, \n",
    "    func=lambda x: (asr_module.transcribe_chunk(x), ser_module.recognize_chunk(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a034c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Stopped listening.know yeah sure without having to test and testing testing also gives the i relax straight cool this is really cool well done very very good', ('neu', {'Arousal': 0.5603644251823425, 'dominance': 0.5963592529296875, 'valence': 0.8236203193664551}))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/LUCID/Folly/Speech/src/stream.py:56\u001b[0m, in \u001b[0;36mStreamer.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mis_active():\n\u001b[0;32m---> 56\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:        \n\u001b[1;32m     58\u001b[0m     stream\u001b[38;5;241m.\u001b[39mstop_stream()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "streamer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d798abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
